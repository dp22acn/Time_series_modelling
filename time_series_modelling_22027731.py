# -*- coding: utf-8 -*-
"""Time series modelling_22027731.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IUYZG8h0Gfm8vTPsVU7cwAxyDOiH5d8h

# Time Series Modelling, Forecast Case Study

# Johnson & Johnson Dataset

## Import necessary libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from itertools import product
from sklearn.metrics import mean_squared_error
from tqdm import tqdm_notebook
import warnings
from statsmodels.graphics.tsaplots import plot_pacf, plot_acf
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tsa.stattools import adfuller
import os
import pathlib

warnings.filterwarnings('ignore')
plt.rcParams['figure.figsize'] = [10, 7.5]

pip install pmdarima

# CodeGrade Tag Init1
from google.colab import drive
drive.mount('/content/drive')

# Import necessary libraries
import pandas as pd

# File path to the CSV file
file_path = "/content/drive/MyDrive/jj.csv"

# Read the CSV file into a DataFrame
data = pd.read_csv(file_path)

# Display the first few rows of the DataFrame to inspect the data
print(data.head())

# Display information about the DataFrame to understand the data types and check for missing values
print(data.info())

import matplotlib.pyplot as plt

# Plot the Johnson & Johnson Quarterly Sales
data['data'].plot(title='Johnson & Johnson Quarterly Sales', figsize=(10, 6))

# Label the y-axis as 'Sales'
plt.ylabel('Sales')

# Label the x-axis as 'Year'
plt.xlabel('Year')

# Display the plot
plt.show()

"""## Plotting Auto Correlation Function (ACF) and Partial Auto Correlation Function (PACF)"""

# Plotting Auto Correlation Function (ACF)
plot_acf(data['data'], color='green')
plt.title('Auto Correlation Function (ACF)')
plt.xlabel('Lags')
plt.ylabel('ACF')
plt.show()

# Plotting Partial Auto Correlation Function (PACF)
plot_pacf(data['data'], color='green')
plt.title('Partial Auto Correlation Function (PACF)')
plt.xlabel('Lags')
plt.ylabel('PACF')
plt.show()

"""## Augmented Dickey-Fuller Test (ADF) for stationarity check"""

# Markdown: Performing Augmented Dickey-Fuller Test (ADF) for stationarity check
result = adfuller(data['data'])

# Display ADF Statistic and p-value
print('ADF Statistic:', result[0])
print('p-value:', result[1])

# Display Critical Values for different confidence levels
print('Critical Values:')
for key, value in result[4].items():
    print('\t%s: %.3f' % (key, value))

"""## Check if the data is stationary"""

# Take the logarithm of the data
data['log_data'] = np.log(data['data'])

# Difference the logarithm data to make it stationary
data['diff_log_data'] = data['log_data'].diff()

"""## Find the best ARMA"""

# Manual approach to find the best SARIMA model
min_aic = float('inf')
best_order = None

for p in range(9):
    for d in range(2):
        for q in range(9):
            try:
                model = SARIMAX(data['data'], order=(p, d, q))
                results = model.fit(disp=False)
                if results.aic < min_aic:
                    min_aic = results.aic
                    best_order = (p, d, q)
            except:
                continue

print("Best AIC (Manual):", min_aic)
print("Best Order (Manual):", best_order)

# Automated model selection using pmdarima
import pmdarima as pm

auto_model = pm.auto_arima(data['data'], start_p=0, start_q=0,
                           max_p=8, max_q=8, seasonal=False,
                           d=None, trace=True, error_action='ignore',
                           suppress_warnings=True, stepwise=True)
print("Best AIC (Auto):", auto_model.aic())
print(auto_model.summary())

"""## Summary of the best model"""

# Create the best SARIMA model based on manual approach
best_model = SARIMAX(data['data'], order=best_order)

# Fit the best model to the data
best_model_fit = best_model.fit()

# Display the summary of the best model
print("Best Model Summary:")
print(best_model_fit.summary())

# Plot diagnostics for the best model
best_model_fit.plot_diagnostics()
plt.show()

"""## Forecast for the next 24 months"""

# number of forecasts
n_forecast = 24

# forecast using the best model
predict = best_model_fit.get_prediction(end=len(data['data']) + n_forecast)

# index for plotting
idx = np.arange(len(predict.predicted_mean))

# Plot the forecast
fig, ax = plt.subplots(figsize=(10, 6))  # Adjusted figsize
ax.plot(data['data'], 'orange', label='Actual Sales', linewidth=2)  # Changed plot color to blue
ax.plot(idx[-n_forecast:], predict.predicted_mean[-n_forecast:], 'green', linestyle='--', label='Forecasted Sales', linewidth=2)  # Changed plot color to green and linestyle to '--'
ax.set(title='Forecast of Johnson&Johnson Sales', xlabel='Time', ylabel='Sales')
ax.legend()
plt.show()

"""## Predicted mean values"""

# forecast intervals using the best model
predictions_int = best_model_fit.get_forecast(steps=24)

# the predicted mean from forecast intervals
predicted_mean = predictions_int.predicted_mean

# Display the predicted mean values
print("Predicted Mean Values:")
print(predicted_mean)

"""## Forecast of Johnson & Johnson Dataset with confidence intervals"""

# forecast intervals using the best model
predictions_int = best_model_fit.get_forecast(steps=24)
confidence_intervals = predictions_int.conf_int()

# index for plotting
idx = np.arange(len(predict.predicted_mean))

# plot the Forecast with Confidence Intervals
plt.figure(figsize=(12, 6))
plt.plot(data['data'], color='blue', label='Actual Sales')
plt.plot(idx[-n_forecast:], predict.predicted_mean[-n_forecast:], color='orange', label='Forecast')  # Changed plot color to orange
plt.fill_between(idx[-n_forecast:], confidence_intervals.iloc[-n_forecast:, 0], confidence_intervals.iloc[-n_forecast:, 1], color='green', alpha=0.5, label='Confidence Interval')  # Changed confidence interval color to green

plt.title('Forecast of Johnson & Johnson Sales with Confidence Intervals')
plt.xlabel('Time')
plt.ylabel('Sales')
plt.legend()
plt.show()

"""## Components of the data using Fourier transforms"""

from scipy.signal import welch

# Power Spectral Density using FFT
fft_vals = np.fft.fft(data['data'])
psd = np.abs(fft_vals) ** 2

# Periodogram
frequencies, power_density = welch(data['data'])

# Power Spectral Density plot
plt.figure(figsize=(12, 6))
plt.plot(psd, color='green', label='Power Spectral Density')  # Changed plot color to green
plt.xlabel('Frequency')
plt.ylabel('Power')
plt.legend()
plt.title('Power Spectral Density of Johnson & Johnson Sales Data')
plt.show()

# Periodogram plot
plt.figure(figsize=(12, 6))
plt.plot(frequencies, power_density, color='orange', label='Periodogram')  # Changed plot color to orange
plt.xlabel('Frequency')
plt.ylabel('Power Density')
plt.legend()
plt.title('Periodogram of Johnson & Johnson Sales Data')
plt.show()

"""# Amazon Dataset"""

import pandas as pd

# Path to the CSV file
file_path = "/content/drive/MyDrive/AMZN.csv"
# Read the CSV file
df = pd.read_csv(file_path)
print(df.head())
print(df.info())

"""## Explore the dataset"""

# Visualize the closing share price data with changed plot color to green
plt.figure(figsize=(10, 6))
plt.plot(df['Close'], color='green')
plt.title('Amazon Closing Share Price Over Time')
plt.xlabel('Time')
plt.ylabel('Closing Share Price')
plt.show()

"""## Check ACF and PACF"""

# Check ACF and PACF
plt.figure(figsize=(10, 6))

# Plot ACF
plot_acf(df['Close'], color='green')
plt.title('Autocorrelation Function (ACF) of Amazon Closing Share Price')
plt.xlabel('Lag')
plt.ylabel('ACF')
plt.show()

plt.figure(figsize=(10, 6))

# Plot PACF
plot_pacf(df['Close'], color='green')
plt.title('Partial Autocorrelation Function (PACF) of Amazon Closing Share Price')
plt.xlabel('Lag')
plt.ylabel('PACF')
plt.show()

"""## Augmented Dickey-Fuller (ADF) test for stationarity"""

result_amzn = adfuller(df['Close'])

# ADF test results
print('ADF Statistic:', result_amzn[0])
print('p-value:', result_amzn[1])
print('Critical Values:')
for key, value in result_amzn[4].items():
    print('\t%s: %.3f' % (key, value))

"""## Find the best ARMA model fit for AMZN dataset"""

from pmdarima import auto_arima

# Find the best ARMA(p,q) model fit for AMZN dataset
auto_model_amzn = auto_arima(df['Close'], start_p=0, start_q=0,
                             max_p=8, max_q=8, seasonal=False,
                             d=None, trace=True, error_action='ignore',
                             suppress_warnings=True, stepwise=True)

# Display the summary of the best ARMA model fit
print("Best ARMA Model Summary:")
print(auto_model_amzn.summary())

from statsmodels.tsa.statespace.sarimax import SARIMAX

# Fit the best SARIMAX model
best_order = auto_model_amzn.order
best_model_amzn = SARIMAX(df['Close'], order=(best_order[0], 0, best_order[1]))
best_model_fit_amzn = best_model_amzn.fit()

# summary of the best SARIMAX model fit
print("Best SARIMAX Model Summary:")
print(best_model_fit_amzn.summary())

# Plot diagnostics for the best SARIMAX model fit
best_model_fit_amzn.plot_diagnostics()
plt.show()