{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOAP43cLExzT8G4Y+f3H4PW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dp22acn/Time_series_modelling/blob/main/Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name: Devendra Sai Peddoju\n",
        "ID: 22027731"
      ],
      "metadata": {
        "id": "CdG5MsJm3ybR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image Segmentation Using Mask Rcnn**"
      ],
      "metadata": {
        "id": "tBRbK8s6TPmG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mask Rcnn Frame Work For Instant Segmentation\n",
        "\n",
        "citation: K. He, G. Gkioxari, P. Dollár and R. Girshick, \"Mask R-CNN,\" 2017 IEEE International Conference on Computer Vision (ICCV), Venice, Italy, 2017, pp. 2980-2988, doi: 10.1109/ICCV.2017.322. keywords: {Feature extraction;Image segmentation;Object detection;Semantics;Quantization (signal);Robustness},\n",
        "\n",
        "\n",
        "\n",
        "![8237584-fig-1-source-small.gif](data:image/gif;base64,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)"
      ],
      "metadata": {
        "id": "STGU9tFGTPpF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataSet: Using a Sub set of Coco 2017 Dataset\n",
        "link to Data set: https://drive.google.com/file/d/1-51jtgTpHDeK8os0GaraF2mocS460xFD/view?usp=sharing\n",
        "\n",
        "citation: @article{lin2014microsoft,\n",
        "  title={Microsoft COCO: Common Objects in Context},\n",
        "  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Dollár, Piotr and Zitnick, C Lawrence},\n",
        "  journal={arXiv preprint arXiv:1405.0312},\n",
        "  year={2014}\n",
        "}"
      ],
      "metadata": {
        "id": "U4RzNNEuTPrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Importing and unpacking the data set\n",
        "!unzip /content/drive/MyDrive/RM_Segmentation_Assignment_dataset.zip -d data_set"
      ],
      "metadata": {
        "id": "E1Q4-MgIWqYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installing Necessary Libabires like Torch Vision can be useful for image processing and gives us acess to use pretrained models for the analysis**\n",
        "\n",
        "**pycocotools is specialized for handling COCO-style datasets, essential for loading, processing, and evaluating your segmentation tasks.**\n",
        "\n",
        "citation and credits:\n",
        "@inproceedings{paszke2019pytorch,\n",
        "  title={PyTorch: An Imperative Style, High-Performance Deep Learning Library},\n",
        "  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},\n",
        "  booktitle={Advances in Neural Information Processing Systems},\n",
        "  volume={32},\n",
        "  year={2019}\n",
        "}\n",
        "\n",
        "TorchVision: https://github.com/pytorch/vision"
      ],
      "metadata": {
        "id": "M16Fn3ymVw8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision pycocotools #installing the libraries"
      ],
      "metadata": {
        "id": "G1tltik1Vwec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing required Lib for the Project"
      ],
      "metadata": {
        "id": "NYnJPgbwYBj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pycocotools.coco import COCO\n",
        "from PIL import Image\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from matplotlib import patches\n",
        "from pycocotools import mask as coco_mask"
      ],
      "metadata": {
        "id": "iIY4JJAAYKaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the categories of interest dynamically\n",
        "classes_of_interest = {\n",
        "    \"vehicle\": [\"truck\", \"car\"],\n",
        "    \"nature\": [\"road\"],\n",
        "    \"human\": [\"person\"]\n",
        "}\n",
        "\n",
        "# Flattenimg  the dictionary to get a list of all class names\n",
        "selected_classes = [cls for sublist in classes_of_interest.values() for cls in sublist]\n",
        "print(\"Classes of interest:\", selected_classes)"
      ],
      "metadata": {
        "id": "SOkQCuWVYnO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acessing the Data Set it Improves the Scalibility, you can modify the function instead of updating multiple hardcoded values."
      ],
      "metadata": {
        "id": "Q7TyylY-ZobG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def get_dataset_paths(base_dir):\n",
        "    \"\"\"\n",
        "    Generating dataset pathsv.\n",
        "\n",
        "    Args:\n",
        "        base_dir (str): The root directory of the dataset.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing paths to training, validation, and test datasets.\n",
        "    \"\"\"\n",
        "    paths = {\n",
        "        \"train_images_dir\": os.path.join(base_dir, \"train-300\", \"data\"),\n",
        "        \"train_annotations_path\": os.path.join(base_dir, \"train-300\", \"labels.json\"),\n",
        "        \"val_images_dir\": os.path.join(base_dir, \"validation-300\", \"data\"),\n",
        "        \"val_annotations_path\": os.path.join(base_dir, \"validation-300\", \"labels.json\"),\n",
        "        \"test_images_dir\": os.path.join(base_dir, \"test-30\")\n",
        "    }\n",
        "    return paths\n",
        "\n",
        "# Set the base directory for the dataset\n",
        "data_dir = \"/content/data_set\"\n",
        "dataset_paths = get_dataset_paths(data_dir)\n",
        "\n",
        "# Access the paths\n",
        "train_images_dir = dataset_paths[\"train_images_dir\"]\n",
        "train_annotations_path = dataset_paths[\"train_annotations_path\"]\n",
        "val_images_dir = dataset_paths[\"val_images_dir\"]\n",
        "val_annotations_path = dataset_paths[\"val_annotations_path\"]\n",
        "test_images_dir = dataset_paths[\"test_images_dir\"]\n",
        "\n",
        "print(\"Dataset paths:\")\n",
        "for key, path in dataset_paths.items():\n",
        "    print(f\"{key}: {path}\")\n"
      ],
      "metadata": {
        "id": "AIyx6LNLZU1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Instance Annotations For our Data it helps us to find the different instances for the same class by Using Functions Like bound Boxes and segmentation Masks.**"
      ],
      "metadata": {
        "id": "a-J4hpNXakhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pycocotools.coco import COCO\n",
        "\n",
        "# Initialize COCO API for instance annotations\n",
        "coco = COCO(train_annotations_path)\n",
        "cat_ids = coco.getCatIds()\n",
        "categories = coco.loadCats(cat_ids)\n",
        "\n",
        "\n",
        "def load_coco_categories(train_annotations_path):\n",
        "    \"\"\"\n",
        "    This function Initialize the COCO API for instance annotations and load category information.\n",
        "\n",
        "    Args:\n",
        "        annotations_path (str): Path to the annotation file\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - names_cats (list): A list of category names.\n",
        "            - names_scats (set): A set of unique supercategory names.\n",
        "    \"\"\"\n",
        "    # Load category IDs and category details\n",
        "    cat_ids = coco.getCatIds()\n",
        "    categories = coco.loadCats(cat_ids)\n",
        "\n",
        "    # Extract category names\n",
        "    names_cats = [cats[\"name\"] for cats in categories]\n",
        "    print(len(names_cats), \"COCO categories:\", \" \".join(names_cats))\n",
        "\n",
        "    # Extract unique supercategory names\n",
        "    names_scats = set([cats[\"supercategory\"] for cats in categories])\n",
        "    print(len(names_scats), \"COCO supercategories:\", \" \".join(names_scats))\n",
        "\n",
        "    return names_cats, names_scats,\n",
        "\n",
        "\n",
        "load_coco_categories(train_annotations_path)\n"
      ],
      "metadata": {
        "id": "hwKsOVLzbP6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensuring Data Distrubution And Quality\n",
        "by calculating the number of images in our class of intrest\n",
        "**The goal is to count the number of images that have at least one instance of each category.**"
      ],
      "metadata": {
        "id": "QuJhogoHeCzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def get_category_image_counts(coco, classes_of_interest):\n",
        "    \"\"\"\n",
        "    Calculate the number of images containing specified categories in the dataset.\n",
        "\n",
        "    Args:\n",
        "        coco (COCO): Initialized COCO API instance.\n",
        "        classes_of_interest (list): List of category names to count in the dataset.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary mapping category names to the count of images containing that category.\n",
        "    \"\"\"\n",
        "    # Dictionary to store the number of images per category\n",
        "    category_image_counts = defaultdict(int)\n",
        "\n",
        "    for category in classes_of_interest:\n",
        "        # Retrieve category IDs for the category\n",
        "        category_IDs = coco.getCatIds(catNms=[category])\n",
        "\n",
        "        if category_IDs:  # Ensure category exists in the dataset\n",
        "            # Get all image IDs for the category\n",
        "            image_IDs = coco.getImgIds(catIds=category_IDs)\n",
        "            category_image_counts[category] = len(image_IDs)\n",
        "            print(f\"Number of images containing {category} category: {len(image_IDs)}.\")\n",
        "        else:\n",
        "            # If category does not exist, report 0\n",
        "            category_image_counts[category] = 0\n",
        "            print(f\"{category} category not found in the dataset.\")\n",
        "\n",
        "    return category_image_counts\n",
        "\n",
        "# Example usage\n",
        "# Define more categories if needed (adjust based on the dataset)\n",
        "classes_of_interest = [\"truck\", \"car\", \"tree\", \"person\", \"dog\", \"cat\", \"bicycle\", \"train\", \"traffic light\"]\n",
        "category_counts = get_category_image_counts(coco, classes_of_interest)\n"
      ],
      "metadata": {
        "id": "4Fx74J-bsmvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Displaying The Categories Plot"
      ],
      "metadata": {
        "id": "1hoRg8wctZWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "colors = sns.color_palette(\"Set2\", len(classes_of_interest))\n",
        "fig, ax = plt.subplots(figsize=(15, 8))\n",
        "bars = ax.bar(category_counts.keys(), category_counts.values(), color=colors)\n",
        "\n",
        "# Adding count labels\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    ax.annotate('{}'.format(height),\n",
        "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                xytext=(0, 3),\n",
        "                textcoords=\"offset points\",\n",
        "                ha='center', va='bottom', fontsize=12)\n",
        "\n",
        "# Adding legend\n",
        "ax.legend(bars, category_counts.keys(), loc='upper left', bbox_to_anchor=(1, 1))\n",
        "\n",
        "# Adding labels\n",
        "ax.set_xlabel('Category', fontsize=14)\n",
        "ax.set_ylabel('Number of Images', fontsize=14)\n",
        "ax.set_title('Number of Images Containing Each Specified Category', fontsize=16)\n",
        "plt.xticks(rotation=45, ha='right', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "L6-7AjSutAwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# loading and displaying a random image along with its corresponding instance annotations from the COCO dataset\n",
        "This part includes fetching random Imags and loading theis instance annotations"
      ],
      "metadata": {
        "id": "_Hy9YfTLvWfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of images to display\n",
        "num_images = 4\n",
        "\n",
        "# Preparing the figure for displaying original and annotated images\n",
        "fig, axes = plt.subplots(num_images, 2, figsize=(15, 5 * num_images))\n",
        "axes = axes.flatten()  # Flattening axes for easier indexing\n",
        "\n",
        "for i in range(num_images):\n",
        "    img_ids = coco.getImgIds()\n",
        "    img_id = random.choice(img_ids)  # Chooses a random image ID\n",
        "    img_info = coco.loadImgs(img_id)[0]  # Get the image info\n",
        "\n",
        "    image_path = os.path.join(train_images_dir, img_info['file_name'])\n",
        "\n",
        "    # Load the image\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "    # Load instance annotations\n",
        "    ann_ids = coco.getAnnIds(imgIds=img_info['id'], catIds=cat_ids, iscrowd=None)\n",
        "    anns = coco.loadAnns(ann_ids)\n",
        "\n",
        "    # Display the original image\n",
        "    ax = axes[2 * i]  # Even-indexed axes for original image\n",
        "    ax.imshow(image)\n",
        "    ax.axis('off')\n",
        "    ax.set_title(f\"Original Image\\nID: {img_info['id']}\")\n",
        "\n",
        "    # Display the image with annotations\n",
        "    ax = axes[2 * i + 1]  # Odd-indexed axes for annotated image\n",
        "    ax.imshow(image)\n",
        "    ax.axis('off')\n",
        "\n",
        "    if anns:\n",
        "        for ann in anns:\n",
        "            # Get bounding box and category info\n",
        "            bbox = ann['bbox']\n",
        "            category_id = ann['category_id']\n",
        "            category_name = coco.loadCats([category_id])[0]['name']\n",
        "\n",
        "            # Drawing the bounding box\n",
        "            rect = patches.Rectangle(\n",
        "                (bbox[0], bbox[1]), bbox[2], bbox[3],\n",
        "                linewidth=2, edgecolor='r', facecolor='none'\n",
        "            )\n",
        "            ax.add_patch(rect)\n",
        "\n",
        "            # Adding the category label\n",
        "            ax.text(bbox[0], bbox[1], category_name, color='red', fontsize=10, weight='bold')\n",
        "\n",
        "            # If the annotation has a segmentation mask, view it\n",
        "            if 'segmentation' in ann and isinstance(ann['segmentation'], list):\n",
        "                for seg in ann['segmentation']:\n",
        "                    # Decode the segmentation polygons\n",
        "                    poly = np.array(seg).reshape((int(len(seg) / 2), 2))  # Reshape into (N, 2) points\n",
        "                    ax.fill(poly[:, 0], poly[:, 1], alpha=0.5, facecolor='yellow', edgecolor='red')\n",
        "\n",
        "        ax.set_title(f\"Annotated Image\\nID: {img_info['id']}\")\n",
        "    else:\n",
        "        ax.set_title(f\"Annotated Image\\nID: {img_info['id']}\\nNo annotations\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "a51dAD1Dtqhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Lib For segmentation\n",
        "**torch** is a framework used to create deep learning models and computation\n",
        "citation: Paszke, A., Gross, S., & Chintala, S. (2017). Automatic differentiation in PyTorch. In NIPS 2017.\n",
        "\n",
        "# Mask Rcnn Resnet50 Fpn\n",
        "This is a pre-trained Mask R-CNN model with a ResNet-50 backbone and Feature Pyramid Networks (FPN), specifically designed for instance segmentation.\n",
        "\n",
        "Citation:He, K., Gkioxari, G., Dollár, P., & Girshick, R. (2017). Mask R-CNN. In ICCV 2017.\n"
      ],
      "metadata": {
        "id": "LBbljZR-z1a9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CocoDetection\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor"
      ],
      "metadata": {
        "id": "TMj5gkvv09p1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IMG_SEG_Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, annotation, transforms=None):\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "        self.coco = COCO(annotation)\n",
        "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Own coco file\n",
        "        coco = self.coco\n",
        "        # Image ID\n",
        "        img_id = self.ids[index]\n",
        "        # List: get annotation id from coco\n",
        "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
        "        # Dictionary: target coco_annotation file for an image\n",
        "        coco_annotation = coco.loadAnns(ann_ids)\n",
        "        # path for input image\n",
        "        path = coco.loadImgs(img_id)[0]['file_name']\n",
        "        # open the input image\n",
        "        img = Image.open(os.path.join(self.root, path)).convert(\"RGB\")\n",
        "\n",
        "        # number of objects in the image\n",
        "        num_objs = len(coco_annotation)\n",
        "\n",
        "        # Bounding boxes for objects\n",
        "        # In coco format, bbox = [xmin, ymin, width, height]\n",
        "        # In pytorch, the input should be [xmin, ymin, xmax, ymax]\n",
        "        boxes = []\n",
        "        masks = []\n",
        "        for i in range(num_objs):\n",
        "            xmin = coco_annotation[i]['bbox'][0]\n",
        "            ymin = coco_annotation[i]['bbox'][1]\n",
        "            xmax = xmin + coco_annotation[i]['bbox'][2]\n",
        "            ymax = ymin + coco_annotation[i]['bbox'][3]\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "            if 'segmentation' in coco_annotation[i] and len(coco_annotation[i]['segmentation']) > 0:\n",
        "                try:\n",
        "                    mask = coco.annToMask(coco_annotation[i])\n",
        "                    masks.append(mask)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error creating mask for annotation {coco_annotation[i]}: {e}\")\n",
        "                    masks.append(torch.zeros((img.height, img.width), dtype=torch.uint8))\n",
        "            else:\n",
        "                # Create an empty mask if no valid segmentation is available\n",
        "                masks.append(torch.zeros((img.height, img.width), dtype=torch.uint8))\n",
        "\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        if len(masks) > 0:\n",
        "            masks = np.stack(masks, axis=0)\n",
        "            masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
        "        else:\n",
        "            masks = torch.zeros((0, img.height, img.width), dtype=torch.uint8)\n",
        "        # Labels\n",
        "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
        "        # Tensorise img_id\n",
        "        img_id = torch.tensor([img_id])\n",
        "        # Size of bbox (Rectangular)\n",
        "        areas = []\n",
        "        for i in range(num_objs):\n",
        "            areas.append(coco_annotation[i]['area'])\n",
        "        areas = torch.as_tensor(areas, dtype=torch.float32)\n",
        "        # Iscrowd\n",
        "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
        "\n",
        "        # Annotation is in dictionary format\n",
        "        my_annotation = {}\n",
        "        my_annotation[\"boxes\"] = boxes\n",
        "        my_annotation[\"labels\"] = labels\n",
        "        my_annotation[\"image_id\"] = img_id\n",
        "        my_annotation[\"area\"] = areas\n",
        "        my_annotation[\"iscrowd\"] = iscrowd\n",
        "        my_annotation[\"masks\"] = masks\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        return img, my_annotation\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)"
      ],
      "metadata": {
        "id": "0izMN1W61500"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transform():\n",
        "    custom_transforms = []\n",
        "    custom_transforms.append(torchvision.transforms.ToTensor())\n",
        "    return torchvision.transforms.Compose(custom_transforms)"
      ],
      "metadata": {
        "id": "7VmU8xbKiBnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the desired classes\n",
        "desired_classes = [\"truck\", \"car\", \"tree\", \"person\", \"dog\", \"cat\", \"bicycle\", \"train\", \"traffic light\"]\n",
        "\n",
        "# Load COCO dataset\n",
        "train_dataset = IMG_SEG_Dataset(train_images_dir,\n",
        "                             train_annotations_path,\n",
        "                             get_transform())\n",
        "\n",
        "val_dataset = IMG_SEG_Dataset(val_images_dir,\n",
        "                           val_annotations_path,\n",
        "                           get_transform())"
      ],
      "metadata": {
        "id": "Y7JnfXFkiDil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter COCO dataset for desired classes based on names\n",
        "target_class_ids = train_dataset.coco.getCatIds(catNms=desired_classes)\n",
        "train_dataset.ids = [img_id for img_id in train_dataset.ids if\n",
        "                     any(annotation['category_id'] in target_class_ids for annotation in\n",
        "                         train_dataset.coco.loadAnns(train_dataset.coco.getAnnIds(imgIds=img_id)))]\n",
        "\n",
        "target_class_ids = val_dataset.coco.getCatIds(catNms=desired_classes)\n",
        "val_dataset.ids = [img_id for img_id in val_dataset.ids if\n",
        "                   any(annotation['category_id'] in target_class_ids for annotation in\n",
        "                       val_dataset.coco.loadAnns(val_dataset.coco.getAnnIds(imgIds=img_id)))]\n",
        "\n",
        "# Check if there are images left after filtering\n",
        "if len(train_dataset) == 0 or len(val_dataset) == 0:\n",
        "    raise ValueError(\"No images found for the specified classes. Please check your filtering criteria.\")\n",
        "\n",
        "num_classes = len(desired_classes) + 1"
      ],
      "metadata": {
        "id": "me3cFaQTiGHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Architecture** MaskRCNN\n",
        "\n",
        "**Back Bone: Using ResNet50 paird with Fpn**\n",
        "\n",
        "**Region PRoposal Network(RPN): is a fully convolutional network itgenerates regions and outputs both bound box co-ordinates and objectness score**\n",
        "\n",
        "**ROI align: After RPN generates regions using ROI aglin to extract feature maps from those regions**\n",
        "\n",
        "**Classifier: Box Classifier**\n",
        "\n",
        "**predictor: Mask predictor**\n",
        "\n",
        "Source Credits:\n",
        "Mask R-CNN Paper: https://arxiv.org/abs/1703.06870\n",
        "Torchvision Documentation: https://pytorch.org/vision/stable/index.html#torchvision\n",
        "ResNet Architecture:https://arxiv.org/abs/1512.03385"
      ],
      "metadata": {
        "id": "hv8_GgvT6i13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6KnAjjYc-Hu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
        "\n",
        "\n",
        "# Define the function to load your model with the specified number of classes\n",
        "def get_image_segmentation(num_classes, pretrained=True):\n",
        "    \"\"\"\n",
        "    Load a Mask R-CNN model with the specified number of classes.\n",
        "\n",
        "    Args:\n",
        "        num_classes (int): Number of classes (including background).\n",
        "        pretrained (bool): Whether to load pre-trained weights or not.\n",
        "\n",
        "    Returns:\n",
        "        model: The Mask R-CNN model with custom classification and mask heads.\n",
        "    \"\"\"\n",
        "    model = maskrcnn_resnet50_fpn(pretrained=pretrained)\n",
        "\n",
        "    # Get number of input features for the classifier\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    # Replace the classifier head to match the desired number of classes\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    # Get number of input features for the mask classifier\n",
        "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "    hidden_layer = 512\n",
        "    # Replace the mask predictor with a new one\n",
        "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define number of classes (background + your target classes)\n",
        "num_classes = len(desired_classes) + 1  # Including background\n",
        "\n",
        "# Instantiate the model\n",
        "model = get_image_segmentation(num_classes, pretrained=True)\n",
        "\n",
        "# Define collate_fn for batch processing (necessary for working with variable-sized inputs)\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "# Define training and validation data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=4, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=4, collate_fn=collate_fn)\n",
        "\n",
        "# Example print of the model architecture\n",
        "print(model)\n"
      ],
      "metadata": {
        "id": "cClmw6xH4F_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Function to select device (GPU if available, otherwise CPU)\n",
        "def get_device():\n",
        "    if torch.cuda.is_available():\n",
        "        # Use the first GPU\n",
        "        device = torch.device(\"cuda:0\")\n",
        "        print(f\"CUDA is available. Using device: {device}\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"CUDA is not available. Using CPU.\")\n",
        "\n",
        "    return device\n",
        "\n",
        "# Function to move model to the appropriate device (GPU or CPU)\n",
        "def move_model_to_device(model, device):\n",
        "    # Moving the model to the selected device (GPU or CPU)\n",
        "    model = model.to(device)\n",
        "    print(f\"Model moved to {device}.\")\n",
        "    return model\n",
        "\n",
        "# Select the device (GPU or CPU)\n",
        "device = get_device()\n",
        "\n",
        "# Example: Moving the model to the selected device\n",
        "model = move_model_to_device(model, device)\n"
      ],
      "metadata": {
        "id": "Ts7IvE3_CL_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Optimizers and Learning Rate**\n",
        "**Stochastic Gradient Descent (SGD)**\n",
        "source:https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#sgd\n",
        "citation:https://arxiv.org/abs/1412.6980\n",
        "\n",
        "**Adam Optimizer**\n",
        "source:https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#adam\n",
        "citation:Kingma, D. P., & Ba, J. (2015). \"Adam: A Method for Stochastic Optimization.\" International Conference on Learning Representations (ICLR). https://arxiv.org/abs/1412.6980\n",
        "\n",
        "Learning Rate Scheduler: StepLR\n",
        "source:https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html#steplr\n",
        "citation:Loshchilov, I., & Hutter, F. (2016). \"SGDR: Stochastic Gradient Descent with Warm Restarts.\" International Conference on Machine Learning (ICML). https://arxiv.org/abs/1608.03983\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Jqon6PsUDGgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Define the optimizer with a flexible learning rate and parameters\n",
        "def get_optimizer(model, lr=0.005, momentum=0.9, weight_decay=0.0005, optimizer_type='SGD'):\n",
        "    \"\"\"\n",
        "    Select and return the optimizer for the given model.\n",
        "\n",
        "    Args:\n",
        "    - model: PyTorch model.\n",
        "    - lr: Learning rate.\n",
        "    - momentum: Momentum for SGD.\n",
        "    - weight_decay: Weight decay for regularization.\n",
        "    - optimizer_type: Type of optimizer to use ('SGD', 'Adam', or 'AdamW').\n",
        "\n",
        "    Returns:\n",
        "    - optimizer: The selected optimizer.\n",
        "    \"\"\"\n",
        "    # Filter parameters that require gradients\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "    # Create the optimizer based on the specified type\n",
        "    if optimizer_type == 'SGD':\n",
        "        optimizer = torch.optim.SGD(params, lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
        "        print(f\"Using SGD optimizer with lr={lr}, momentum={momentum}, weight_decay={weight_decay}\")\n",
        "    elif optimizer_type == 'Adam':\n",
        "        optimizer = torch.optim.Adam(params, lr=lr, weight_decay=weight_decay)\n",
        "        print(f\"Using Adam optimizer with lr={lr}, weight_decay={weight_decay}\")\n",
        "    elif optimizer_type == 'AdamW':\n",
        "        optimizer = torch.optim.AdamW(params, lr=lr, weight_decay=weight_decay)\n",
        "        print(f\"Using AdamW optimizer with lr={lr}, weight_decay={weight_decay}\")\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown optimizer type: {optimizer_type}\")\n",
        "\n",
        "    return optimizer\n",
        "\n",
        "# Define the learning rate scheduler (StepLR, could be customized later)\n",
        "def get_lr_scheduler(optimizer, step_size=3, gamma=0.1, scheduler_type='StepLR'):\n",
        "    \"\"\"\n",
        "    Select and return the learning rate scheduler for the given optimizer.\n",
        "\n",
        "    Args:\n",
        "    - optimizer: The optimizer to apply the scheduler to.\n",
        "    - step_size: Number of epochs after which the learning rate should be reduced.\n",
        "    - gamma: The factor by which the learning rate will be multiplied.\n",
        "    - scheduler_type: Type of learning rate scheduler ('StepLR', 'CosineAnnealingLR', or 'ReduceLROnPlateau').\n",
        "\n",
        "    Returns:\n",
        "    - lr_scheduler: The selected learning rate scheduler.\n",
        "    \"\"\"\n",
        "    # Select the scheduler based on the specified type\n",
        "    if scheduler_type == 'StepLR':\n",
        "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "        print(f\"Using StepLR scheduler with step_size={step_size} and gamma={gamma}\")\n",
        "    elif scheduler_type == 'CosineAnnealingLR':\n",
        "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0)\n",
        "        print(f\"Using CosineAnnealingLR scheduler with T_max=10, eta_min=0\")\n",
        "    elif scheduler_type == 'ReduceLROnPlateau':\n",
        "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
        "        print(f\"Using ReduceLROnPlateau scheduler with factor=0.1, patience=5\")\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown scheduler type: {scheduler_type}\")\n",
        "\n",
        "    return lr_scheduler\n",
        "\n",
        "# Example: Get optimizer and scheduler\n",
        "optimizer = get_optimizer(model, lr=0.005, optimizer_type='SGD')\n",
        "lr_scheduler = get_lr_scheduler(optimizer, step_size=3, gamma=0.1)\n"
      ],
      "metadata": {
        "id": "UKVjwX4kDDJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop"
      ],
      "metadata": {
        "id": "fPtVryVeFxq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm  # Import tqdm for the progress bar\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    # Use tqdm to add a progress bar for the training loop\n",
        "    with tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch') as pbar:\n",
        "        for images, targets in pbar:\n",
        "            images = list(image.to(device) for image in images)\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]  # Move targets to device\n",
        "\n",
        "            # Forward pass: calculate loss\n",
        "            loss_dict = model(images, targets)\n",
        "            losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "            # Backward pass: optimize the model\n",
        "            optimizer.zero_grad()\n",
        "            losses.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the progress bar with the current loss\n",
        "            pbar.set_postfix(loss=losses.item())  # Display loss in the progress bar\n",
        "\n",
        "    # Update learning rate\n",
        "    lr_scheduler.step()\n",
        "\n",
        "    # Validate the model\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        # Use tqdm to add a progress bar for the validation loop\n",
        "        with tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} - Validation', unit='batch') as pbar_val:\n",
        "            for images, targets in pbar_val:\n",
        "                images = list(image.to(device) for image in images)\n",
        "                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]  # Move targets to device\n",
        "\n",
        "                # Forward pass during validation\n",
        "                model(images, targets)  # No gradient needed\n",
        "\n",
        "                # You can optionally add validation loss visualization here if required\n",
        "                pbar_val.set_postfix()\n",
        "\n",
        "print(\"Training finished\")\n"
      ],
      "metadata": {
        "id": "js0SVYtjE2KH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image, ImageDraw\n",
        "import torchvision.transforms as T\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Function to perform inference and visualize results\n",
        "def visualize_inference(model, test_images_dir, device, threshold=0.3, num_images=3):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    model.to(device)  # Ensure the model is on the correct device (GPU or CPU)\n",
        "\n",
        "    # List all image files in the test directory\n",
        "    image_files = [f for f in os.listdir(test_images_dir) if os.path.isfile(os.path.join(test_images_dir, f))]\n",
        "    print(f\"Found {len(image_files)} images in {test_images_dir}.\")\n",
        "\n",
        "    # Select random images\n",
        "    if len(image_files) == 0:\n",
        "        print(\"No images found in the test directory.\")\n",
        "        return\n",
        "\n",
        "    selected_images = random.sample(image_files, min(num_images, len(image_files)))\n",
        "\n",
        "    # Loop through each selected image for inference\n",
        "    for image_file in selected_images:\n",
        "        image_path = os.path.join(test_images_dir, image_file)\n",
        "        print(f\"Processing image: {image_file}\")\n",
        "\n",
        "        # Check if image exists\n",
        "        if not os.path.exists(image_path):\n",
        "            print(f\"Image not found at path: {image_path}\")\n",
        "            continue\n",
        "\n",
        "        image = Image.open(image_path).convert(\"RGB\")  # Open image and convert to RGB\n",
        "\n",
        "        # Transform the image to tensor and move to device\n",
        "        image_tensor = T.ToTensor()(image).unsqueeze(0).to(device)\n",
        "\n",
        "        # Perform inference with no gradient calculation\n",
        "        with torch.no_grad():\n",
        "            prediction = model(image_tensor)\n",
        "\n",
        "        # Extract prediction results\n",
        "        boxes = prediction[0]['boxes'].cpu().numpy()\n",
        "        labels = prediction[0]['labels'].cpu().numpy()\n",
        "        scores = prediction[0]['scores'].cpu().numpy()\n",
        "        masks = prediction[0]['masks'].cpu().numpy()\n",
        "\n",
        "        # Debug: Check the number of detected objects\n",
        "        print(f\"Detected {len(boxes)} objects in {image_file}\")\n",
        "\n",
        "        # Print out the range of confidence scores for analysis\n",
        "        print(f\"Confidence scores range: min = {np.min(scores)}, max = {np.max(scores)}\")\n",
        "\n",
        "        # Filter out predictions with low scores (below the threshold)\n",
        "        high_score_idxs = np.where(scores > threshold)[0]\n",
        "        print(f\"After applying threshold ({threshold}), {len(high_score_idxs)} objects remain.\")\n",
        "\n",
        "        if len(high_score_idxs) == 0:\n",
        "            print(f\"No objects detected with sufficient confidence in {image_file}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        # Convert image to RGBA for mask overlay\n",
        "        image_rgba = image.convert(\"RGBA\")\n",
        "        draw = ImageDraw.Draw(image_rgba)\n",
        "\n",
        "        # Use a random color palette for each object mask\n",
        "        colors = [tuple(np.random.randint(0, 255, 3)) for _ in range(len(high_score_idxs))]\n",
        "\n",
        "        # Loop over each prediction to draw boxes, labels, and masks\n",
        "        for idx, color in zip(high_score_idxs, colors):\n",
        "            box = boxes[idx]\n",
        "            mask = masks[idx, 0]  # Get the mask for the object\n",
        "            label = labels[idx]\n",
        "\n",
        "            # drawin bounding box with a random color\n",
        "            draw.rectangle(((box[0], box[1]), (box[2], box[3])), outline=color, width=3)\n",
        "\n",
        "            # creating a mask image with a specific transparency level\n",
        "            mask_image = Image.fromarray((mask * 255).astype(np.uint8), mode='L')\n",
        "            mask_image = mask_image.convert(\"RGBA\")\n",
        "            mask_image.putalpha(128)  # Adjust transparency for better overlay\n",
        "\n",
        "            # applying the mask overlay to the image\n",
        "            image_rgba = Image.alpha_composite(image_rgba, mask_image)\n",
        "\n",
        "            # adding label text and score next to the bounding box\n",
        "            label_text = f\"Class {label}: {scores[idx]:.2f}\"\n",
        "            draw.text((box[0], box[1]), label_text, fill=color)\n",
        "\n",
        "        # Checking if image_rgba is valid before showing\n",
        "        if image_rgba:\n",
        "            plt.figure(figsize=(10, 10))\n",
        "            plt.imshow(image_rgba)\n",
        "            plt.axis('off')\n",
        "            plt.title(f\"Inference Result for {image_file}\")\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(f\"Error: The processed image is empty or invalid for {image_file}\")\n",
        "\n",
        "\n",
        "visualize_inference(model, test_images_dir, device, threshold=0.3)\n"
      ],
      "metadata": {
        "id": "inIkpcFbYEks"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}